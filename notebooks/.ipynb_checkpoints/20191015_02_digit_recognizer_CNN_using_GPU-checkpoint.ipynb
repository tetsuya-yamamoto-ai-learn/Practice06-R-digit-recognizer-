{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "- Notebook版\n",
    "- このNotebookだけで成立するようにしています\n",
    "    - KaggleNotebook や Colaboratory で実行がしやすくなる\n",
    "    - 継続的な改善はしにくいので使い捨てと割り切ったほうがいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:09.645352Z",
     "start_time": "2019-10-16T01:33:03.826003Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPath\n",
    "- パスの管理を任せる\n",
    "- KaggleやColaboratoryで実行する場合は修正が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:09.654202Z",
     "start_time": "2019-10-16T01:33:09.648218Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DataPath(Enum):\n",
    "    Root = Path('../')\n",
    "    Input = Root / 'input'\n",
    "    # Input = Root / 'input/digit-recognizer'  # KaggleNotebookに対応\n",
    "    Submission = Root / 'submissions'\n",
    "\n",
    "    TrainCsv = Input / 'train.csv'\n",
    "    TestCsv = Input / 'test.csv'\n",
    "\n",
    "    SubmissionCsv = Input / 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:09.663178Z",
     "start_time": "2019-10-16T01:33:09.657194Z"
    }
   },
   "outputs": [],
   "source": [
    "# ファイルの存在を確認する\n",
    "assert DataPath.TrainCsv.value.exists()\n",
    "assert DataPath.TestCsv.value.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:09.682131Z",
     "start_time": "2019-10-16T01:33:09.665174Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].reshape(1, 28, 28).astype(np.float32)\n",
    "\n",
    "        label = self.y[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray):\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].reshape(1, 28, 28).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:09.693098Z",
     "start_time": "2019-10-16T01:33:09.685120Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(batch_size):\n",
    "    train = pd.read_csv(DataPath.TrainCsv.value)\n",
    "\n",
    "    X = train.iloc[:, 1:].values\n",
    "    y = train.iloc[:, 0].values\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "\n",
    "                                                          y,\n",
    "                                                          train_size=0.8,\n",
    "                                                          random_state=0)\n",
    "    train_dataset = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_dataset = TrainDataset(X_valid, y_valid)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:13.434070Z",
     "start_time": "2019-10-16T01:33:09.696090Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0175216\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 1. DatasetとDataLoader\n",
    "train_loader, valid_loader = prepare_data_loaders(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:13.453040Z",
     "start_time": "2019-10-16T01:33:13.440068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cpu\n"
     ]
    }
   ],
   "source": [
    "# GPUが利用できるなら使う\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Use {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:13.500891Z",
     "start_time": "2019-10-16T01:33:13.463990Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(3, 6, kernel_size=(2, 2))\n",
    "\n",
    "        self.fc1 = nn.Linear(6 * 6 * 6, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "\n",
    "        x = x.view(-1, 6 * 6 * 6)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:13.567719Z",
     "start_time": "2019-10-16T01:33:13.507898Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 2. モデル(ネットワーク)\n",
    "model: nn.Module = SimpleCNN()\n",
    "model.to(device)  # GPUに転送\n",
    "\n",
    "# 最適化アルゴリズムと損失関数\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:13.594650Z",
     "start_time": "2019-10-16T01:33:13.574695Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def run_train_epoch(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # GPUに転送\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 勾配初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播計算\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 損失の計算\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 重みの更新\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch: {epoch} Train Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    retrun epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def run_valid_epoch(model, valid_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            # GPUに転送\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    print(f'Epoch: {epoch} Valid Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:29.513516Z",
     "start_time": "2019-10-16T01:33:13.600625Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.2754\n",
      "Epoch: 1 Valid Loss: 0.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████▌                                                 | 1/2 [00:08<00:08,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.1084\n",
      "Epoch: 2 Valid Loss: 0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  8.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# 3. 学習\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1)):\n",
    "    run_train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    run_valid_epoch(model, valid_loader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータでの予測とSubmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:29.526483Z",
     "start_time": "2019-10-16T01:33:29.516508Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = np.array([], dtype=np.int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            # GPUに転送\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, y_pred = torch.max(outputs, dim=1)\n",
    "            y_pred_label = y_pred.cpu().numpy()\n",
    "\n",
    "            predictions = np.append(predictions, y_pred_label)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:33.266464Z",
     "start_time": "2019-10-16T01:33:29.533464Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 4. TestDataでの予測\n",
    "df_test = pd.read_csv(DataPath.TestCsv.value)\n",
    "X_test = df_test.values\n",
    "\n",
    "test_dataset = TestDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "predictions = make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:33.274445Z",
     "start_time": "2019-10-16T01:33:33.268459Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def make_submission_file(model, predictions):\n",
    "    submit_data = pd.read_csv(DataPath.SubmissionCsv.value)\n",
    "    submit_data['Label'] = predictions\n",
    "\n",
    "    yymmddhhmmss = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # ex: '20201231_174530_SimpleNet.csv\n",
    "    save_submission_path = f'{yymmddhhmmss}_{model_name}.csv'\n",
    "\n",
    "    submit_data.to_csv(save_submission_path, index=False)\n",
    "    print(f'Saved {save_submission_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T01:33:33.409085Z",
     "start_time": "2019-10-16T01:33:33.278433Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20191016_103333_SimpleCNN.csv\n"
     ]
    }
   ],
   "source": [
    "# submissionの作成\n",
    "make_submission_file(model, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おわり"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
