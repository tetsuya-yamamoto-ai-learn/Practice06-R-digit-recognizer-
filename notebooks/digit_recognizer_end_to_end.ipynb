{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "- Notebook版\n",
    "- このNotebookだけで成立するようにしています\n",
    "    - KaggleNotebook や Colaboratory で実行がしやすくなる\n",
    "    - 継続的な改善はしにくいので使い捨てと割り切ったほうがいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:17.096254Z",
     "start_time": "2019-10-14T11:43:16.509916Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPath\n",
    "- パスの管理を任せる\n",
    "- KaggleやColaboratoryで実行する場合は修正が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:17.118261Z",
     "start_time": "2019-10-14T11:43:17.097373Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DataPath(Enum):\n",
    "    Root = Path('../')\n",
    "    Input = Root / 'input'\n",
    "    Submission = Root / 'submissions'\n",
    "\n",
    "    TrainCsv = Input / 'train.csv'\n",
    "    TestCsv = Input / 'test.csv'\n",
    "\n",
    "    SubmissionCsv = Input / 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:17.142161Z",
     "start_time": "2019-10-14T11:43:17.119535Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx]\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray):\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:17.166125Z",
     "start_time": "2019-10-14T11:43:17.143486Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(batch_size):\n",
    "    train = pd.read_csv(DataPath.TrainCsv.value)\n",
    "\n",
    "    X = train.iloc[:, 1:].values\n",
    "    y = train.iloc[:, 0].values\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "\n",
    "                                                          y,\n",
    "                                                          train_size=0.8,\n",
    "                                                          random_state=0)\n",
    "    train_dataset = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_dataset = TrainDataset(X_valid, y_valid)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:20.173464Z",
     "start_time": "2019-10-14T11:43:17.167254Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# 1. DatasetとDataLoader\n",
    "train_loader, valid_loader = prepare_data_loaders(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:20.199110Z",
     "start_time": "2019-10-14T11:43:20.176522Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MySimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=784, out_features=60)\n",
    "        self.fc2 = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:20.222271Z",
     "start_time": "2019-10-14T11:43:20.201289Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 2. モデル(ネットワーク)\n",
    "model: nn.Module = MySimpleNet()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:20.247995Z",
     "start_time": "2019-10-14T11:43:20.223941Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_train_epoch(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # 勾配初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播計算\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 損失の計算\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 重みの更新\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch: {epoch} Train Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "def run_valid_epoch(model, valid_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    print(f'Epoch: {epoch} Valid Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:25.059659Z",
     "start_time": "2019-10-14T11:43:20.249555Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.6391\n",
      "Epoch: 1 Valid Loss: 0.3832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.3121\n",
      "Epoch: 2 Valid Loss: 0.3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 学習\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1)):\n",
    "    run_train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    run_valid_epoch(model, valid_loader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータでの予測とSubmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:25.083696Z",
     "start_time": "2019-10-14T11:43:25.061413Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = np.array([], dtype=np.int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, y_pred = torch.max(outputs, dim=1)\n",
    "            y_pred_label = y_pred.numpy()\n",
    "\n",
    "            predictions = np.append(predictions, y_pred_label)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:26.756492Z",
     "start_time": "2019-10-14T11:43:25.084854Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 4. TestDataでの予測\n",
    "df_test = pd.read_csv(DataPath.TestCsv.value)\n",
    "X_test = df_test.values\n",
    "\n",
    "test_dataset = TestDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "predictions = make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:26.778963Z",
     "start_time": "2019-10-14T11:43:26.757959Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def make_submission_file(model, predictions):\n",
    "    submit_data = pd.read_csv(DataPath.SubmissionCsv.value)\n",
    "    submit_data['Label'] = predictions\n",
    "\n",
    "    yymmddhhmmss = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # ex: '20201231_174530_SimpleNet.csv\n",
    "    save_submission_path = DataPath.Submission.value / f'{yymmddhhmmss}_{model_name}.csv'\n",
    "\n",
    "    submit_data.to_csv(save_submission_path, index=False)\n",
    "    print(f'Saved {save_submission_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:43:26.871211Z",
     "start_time": "2019-10-14T11:43:26.780899Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../submissions/20191014_204326_MySimpleNet.csv\n"
     ]
    }
   ],
   "source": [
    "# submissionの作成\n",
    "make_submission_file(model, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おわり"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
